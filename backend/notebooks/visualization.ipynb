{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "rs = numpy.random.RandomState(12345)\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/dsuser/workspace/backend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from modules.model.text_classify import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = \"00\"\n",
    "dataset = \"aozora\"\n",
    "pipe = joblib.load(f\"data/model/pipe-jptokenizermecab_{dataset}set_iter{itr}.gz\")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = joblib.load(f\"data/dataset/{dataset}set_iter{itr}.gz\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.shuffle().split()\n",
    "X_train, X_valid = dataset.get_data(do_split=True)\n",
    "y_train, y_valid = dataset.get_labels(do_split=True)\n",
    "len(X_train), len(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with trainset\n",
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict trainset\n",
    "p_train = pipe.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, p_train)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict validset\n",
    "prob_valid = pipe.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = pipe[-1]\n",
    "p_valid = lgbm._le.inverse_transform(prob_valid.argmax(axis=1))\n",
    "valid_acc = accuracy_score(y_valid, p_valid)\n",
    "valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm._le.inverse_transform(range(len(dataset.labelset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.labelset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def plot_pr_curve_by_label(ax, lbl: str, t: numpy.ndarray, p: numpy.ndarray):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(t, p)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    # print(f\"ROC Area / {lbl} : (AUC = {auc:.3f})\")\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(t, p)\n",
    "    ap = metrics.average_precision_score(t, p)\n",
    "\n",
    "    ax.step(recall, precision, color='g', alpha=0.2, where='post')\n",
    "    ax.fill_between(recall, precision, step='post', alpha=0.2, color='g')\n",
    "\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlim([0.0, 1.05])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_title(f'{lbl} : AP={ap:0.3f} / AUC={auc:0.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(dataset, pipe):\n",
    "    n_classes = len(dataset.labelset)\n",
    "    n_rows = int(numpy.sqrt(n_classes))\n",
    "    print(\"n_rows:\", n_rows)\n",
    "\n",
    "    delta = int(bool(n_classes % n_rows))\n",
    "    n = (n_classes // n_rows) * n_rows + n_rows * delta\n",
    "    n_cols = n // n_rows\n",
    "    n_rows -= int(n == n_classes + n_cols)\n",
    "    fig, axes = pyplot.subplots(nrows=n_rows, ncols=n_cols, figsize = (10, 10), squeeze=False, tight_layout=True)\n",
    "    fig.suptitle('PR-Curve', fontsize=16)\n",
    "\n",
    "    lgbm = pipe[-1]\n",
    "    for idx, lbl in enumerate(dataset.labelset):\n",
    "        idx_lbl = lgbm._le.transform([lbl])\n",
    "\n",
    "        t = (numpy.array(y_valid) == lbl).astype(numpy.int32)\n",
    "        p = pipe.predict_proba(X_valid)[:, idx_lbl]\n",
    "\n",
    "        r = idx // n_cols\n",
    "        c = idx % n_cols\n",
    "        plot_pr_curve_by_label(axes[r, c], lbl, t, p)\n",
    "\n",
    "\n",
    "    # show plots\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(dataset, pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pipe[0]\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_text(idx: int):\n",
    "    # sentence = X_valid[idx]\n",
    "    # return \"\".join(sentence)\n",
    "    tokens = tokenizer.transform([X_valid[idx]])[0]\n",
    "    feature = \" \".join(tokens)\n",
    "    return feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "labels_indices = range(len(dataset.labelset))\n",
    "labels = lgbm._le.inverse_transform(labels_indices)\n",
    "explainer = LimeTextExplainer(class_names=labels, split_expression=lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[:5], p_valid[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline を作り直す\n",
    "- LIME　の文分割の処理に合わせて、トークナイザをスプリット処理して、空白を除去し次のパイプライン（CountVectorizer）に渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "_pipe = make_pipeline(Splitter(), pipe[1:])\n",
    "_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model_regressor = Ridge(alpha=1, fit_intercept=True, random_state=rs)\n",
    "\n",
    "def _explain(indices_samples, n_pickup=2):\n",
    "    for idx in indices_samples[:n_pickup]:\n",
    "        print(\"idx:\", idx, f\"actual: {y_valid[idx]}\", f\"prediction: {p_valid[idx]}\")\n",
    "\n",
    "        x = make_feature_text(idx)\n",
    "        print(\"x:\", x[:64])\n",
    "        # exp = explainer.explain_instance(x, _pipe.predict_proba, num_features=10, labels=labels_indices, model_regressor=model_regressor)\n",
    "        exp = explainer.explain_instance(x, _pipe.predict_proba, num_features=10, top_labels=2, model_regressor=model_regressor)\n",
    "        exp.show_in_notebook(text=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_samples_correct = numpy.arange(len(y_valid))[y_valid == p_valid]\n",
    "indices_samples_correct = rs.permutation(indices_samples_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_explain(indices_samples_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_samples_wrong = numpy.arange(len(y_valid))[y_valid != p_valid]\n",
    "indices_samples_wrong = rs.permutation(indices_samples_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_explain(indices_samples_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 911 詩歌 　(1,689件)\n",
    "- 915 日記．書簡．紀行 　(656件)\n",
    "- 913 小説．物語 　(6,329件)\n",
    "    - K913: 子ども・小学生向けの本\n",
    "- 914 評論．エッセイ．随筆 　(4,366件)\n",
    "\n",
    "---\n",
    "\n",
    "- 910 日本文学 　(240件)\n",
    "- 912 戯曲 　(228件)\n",
    "- 916 記録．手記．ルポルタージュ 　(109件)\n",
    "- 917 箴言．アフォリズム．寸言 　(19件)\n",
    "- 918 作品集\n",
    "- 919 漢詩文．日本漢文学 　(4件)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(Splitter(sep=\" \"), pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = indices_samples_correct[0]\n",
    "x = \" \".join(X_valid[idx])\n",
    "x[:200]\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize(x: str) -> list:\n",
    "    sentences = x.split(\" \")\n",
    "    tokenized = tokenizer.transform([sentences])\n",
    "    return tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[idx], p_valid[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_regressor = Ridge(alpha=1, fit_intercept=True, random_state=rs)\n",
    "explainer = LimeTextExplainer(class_names=labels, split_expression=_tokenize)\n",
    "exp = explainer.explain_instance(x, pipe2.predict_proba, num_features=10, top_labels=2, model_regressor=model_regressor)\n",
    "exp.show_in_notebook(text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
