{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "model_file = \"../data/ELYZA-japanese-Llama-2-7b-fast-instruct-q8_0.gguf\"\n",
    "# model_file = \"../data/ELYZA-japanese-Llama-2-13b-fast-instruct-q8_0.gguf\"\n",
    "# model_file = \"./ELYZA-japanese-Llama-2-7b-fast-instruct-q8_0.gguf\"    # self-making\n",
    "# model_file = \"./ELYZA-japanese-CodeLlama-7b-instruct-q8_0.gguf\"       # self-making\n",
    "pathlib.Path(model_file).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "n_gqa = 8 if \"70b\" in model_file else 1\n",
    "llm = Llama(model_path=model_file, n_gqa=n_gqa, n_gpu_layers=16)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"富士山の高さは？正確に\"\"\"\n",
    "# prompt = \"1から20までの間の数で、5で終わる数は？\"\n",
    "\n",
    "prompt_formatted = f\"\"\"[INST] <<SYS>>あなたは誠実で優秀な日本人のアシスタントです。<</SYS>> {prompt} [/INST]\"\"\"\n",
    "\n",
    "\n",
    "# 推論の実行\n",
    "for jsn in llm(\n",
    "    prompt_formatted,\n",
    "    max_tokens=128,\n",
    "    temperature=0.0001,\n",
    "    stop=None,\n",
    "    echo=True,\n",
    "    stream=True,\n",
    "):\n",
    "    print(jsn[\"choices\"][0][\"text\"], sep=\"\", end=\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.llama2cpp.component.llama2cpp import LlamaCppCustom\n",
    "\n",
    "\n",
    "n_gqa = 8 if \"70b\" in model_file else 1\n",
    "llm = LlamaCppCustom(\n",
    "    model_path=model_file,\n",
    "    n_ctx=512,\n",
    "    temperature=0.0001,\n",
    "    max_tokens=1024,\n",
    "    n_gqa=n_gqa,\n",
    "    n_gpu_layers=34,\n",
    "    verbose=True,\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"富士山の高さは？正確に\"\n",
    "# prompt = \"1から20までの間の数で、5で終わる数は？\"\n",
    "\n",
    "prompt_formatted = f\"\"\"[INST] <<SYS>>あなたは誠実で優秀な日本人のアシスタントです。<</SYS>> {prompt} [/INST]\"\"\"\n",
    "\n",
    "text = \"\"\n",
    "# async for tkn in llm.astream(input=prompt_formatted, stop=None):\n",
    "for tkn in llm.stream(input=prompt_formatted, stop=None):\n",
    "    print(tkn, sep=\"\", end=\"\")\n",
    "    text += tkn\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
