{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "sns.set_theme(font=\"IPAexGothic\")\n",
    "pyplot.rcParams[\"figure.figsize\"] = (16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_start_date = datetime.now()\n",
    "g_start_date.strftime(\"%Y/%m/%d %T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.mof.go.jp/jgbs/reference/interest_rate/data/jgbcm_all.csv\"\n",
    "_df = pandas.read_csv(url, header=1, encoding=\"shift-jis\")\n",
    "_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: created by ChatGPT GPT-4\n",
    "def convert_wareki_to_seireki(wareki_date):\n",
    "    \"\"\"\n",
    "    和暦を西暦に変換する関数。\n",
    "    \"\"\"\n",
    "    era = wareki_date[0]\n",
    "    year, month, day = map(int, wareki_date[1:].split(\".\"))\n",
    "\n",
    "    if era == \"S\":  # 昭和\n",
    "        seireki_year = 1925 + year\n",
    "    elif era == \"H\":  # 平成\n",
    "        seireki_year = 1988 + year\n",
    "    elif era == \"R\":  # 令和\n",
    "        seireki_year = 2018 + year\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown era: {era}\")\n",
    "\n",
    "    return f\"{seireki_year}-{month:02}-{day:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[\"ds\"] = pandas.to_datetime(_df[\"基準日\"].apply(convert_wareki_to_seireki))\n",
    "_df[[\"基準日\", \"ds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.replace(\"-\", float(\"nan\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_cols = [col for col in _df.columns if col not in [\"基準日\", \"ds\"]]\n",
    "rate_cols = [\"1年\", \"5年\", \"10年\", \"20年\"]\n",
    "rate_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[rate_cols] = _df[rate_cols].astype(float)\n",
    "_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in rate_cols:\n",
    "    pyplot.plot(_df[\"ds\"], _df[col], label=col)\n",
    "\n",
    "pyplot.title(\"日本国債金利の変動\")\n",
    "pyplot.xlabel(\"ds\")\n",
    "pyplot.ylabel(\"金利 (%)\")\n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df.copy()\n",
    "df.index = pandas.to_datetime(df.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly = df[rate_cols].resample(\"W-MON\").mean()\n",
    "df_weekly.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly = df[rate_cols].resample(\"MS\").mean()\n",
    "# df_monthly[\"2000-01-01\":].plot()\n",
    "df_monthly.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly = df[rate_cols].resample(\"MS\").mean()\n",
    "df_monthly.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from protuna import (\n",
    "    ModelBuilder,\n",
    "    Evaluator,\n",
    "    Limitter,\n",
    "    BestEstimator,\n",
    "    ProphetModelAnalyser,\n",
    "    setup_df_index,\n",
    "    setup_limit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シミュレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_rate_types = rate_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = \"2000-01-01\"\n",
    "start_date = \"2015-01-01\"\n",
    "period_type = \"weekly\"\n",
    "# period_type = \"monthly\"\n",
    "\n",
    "if period_type == \"weekly\":\n",
    "    df0 = df_weekly[start_date:].reset_index()\n",
    "    freq = \"W-MON\"\n",
    "    freq_cv = \"4W-MON\"\n",
    "    # n_horizon = 7 * 4 * 12    # days: about 1 years\n",
    "    # horizon_scaler = 5\n",
    "    # n_predicts = 4 * 12       # freqs: 12か月分\n",
    "    n_horizon = 7 * 4  # days: about 1 month\n",
    "    horizon_scaler = 2\n",
    "    n_predicts = 4 * 1  # freqs: 1か月分\n",
    "else:\n",
    "    df0 = df_monthly[start_date:].reset_index()\n",
    "    freq = \"MS\"\n",
    "    freq_cv = \"3MS\"\n",
    "    n_horizon = 365.25  # days: about 1 year\n",
    "    horizon_scaler = 5\n",
    "    n_predicts = 1 * 12 * 2  # freqs: 2年分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 200 mins\n",
    "\n",
    "bests = {}\n",
    "\n",
    "for rate_type in g_rate_types:\n",
    "    # setup\n",
    "    df = df0.rename({\"年月\": \"ds\", rate_type: \"y\"}, axis=1)[[\"ds\", \"y\"]]\n",
    "    df[\"fake\"] = list(range(len(df)))\n",
    "    lmt = Limitter(df)\n",
    "    df = setup_limit(df, lmt)\n",
    "    evl = Evaluator(\n",
    "        df=df, n_horizon=n_horizon, freq=freq_cv, horizon_scaler=horizon_scaler\n",
    "    )\n",
    "\n",
    "    # optimize hyper params\n",
    "    study: optuna.Study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(evl.objective_value, n_trials=100)\n",
    "\n",
    "    # rerun cv\n",
    "    mb: ModelBuilder = ModelBuilder(df=df)\n",
    "    model: Prophet = mb.build_prophet_model(**study.best_params)\n",
    "    model.fit(df)\n",
    "    df_cv, df_pm = evl.run_cross_validation(model=model)\n",
    "\n",
    "    # predict\n",
    "    future = model.make_future_dataframe(periods=n_predicts, freq=freq)\n",
    "    future[\"fake\"] = list(range(len(future)))\n",
    "    future = setup_limit(future, lmt)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # store estimator\n",
    "    bst = BestEstimator(\n",
    "        df=df,\n",
    "        model=model,\n",
    "        evaluator=evl,\n",
    "        study=study,\n",
    "        df_cv=df_cv,\n",
    "        df_pm=df_pm,\n",
    "        future=future,\n",
    "        forecast=forecast,\n",
    "    )\n",
    "    bests[rate_type] = bst\n",
    "    break  # debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmz = ProphetModelAnalyser(model=model, df=df)\n",
    "beta_fake = pmz.pickup_beta(component=\"fake\")\n",
    "beta_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "future = model.make_future_dataframe(periods=n_predicts, freq=freq)\n",
    "future = setup_limit(future, lmt)\n",
    "future[\"fake\"] = list(range(len(future)))\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "\n",
    "n_years = 1\n",
    "n_predicts = 12 * n_years\n",
    "\n",
    "\n",
    "for rate_type in bests.keys():\n",
    "    bst: BestEstimator = bests[rate_type]\n",
    "\n",
    "    # predict\n",
    "    model: Prophet = bst.model\n",
    "    future = model.make_future_dataframe(periods=n_predicts, freq=freq)\n",
    "\n",
    "    limitter = Limitter(bst.df)\n",
    "    future = setup_limit(future, limitter)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # plot prediction\n",
    "    fig: pyplot.Figure = model.plot(forecast, figsize=(20, 10))\n",
    "    fig.suptitle(f\"実績と予測: {rate_type}\", x=0.5, y=1.02, size=16)\n",
    "    pyplot.axvline(bst.df.ds.iloc[-1], color=\"b\", linestyle=\"--\", lw=1)\n",
    "    fig.show()\n",
    "\n",
    "    # plot components\n",
    "    fig = model.plot_components(forecast, figsize=(20, 20))\n",
    "    fig.suptitle(f\"コンポーネント: {rate_type}\", x=0.5, y=1.02, size=16)\n",
    "    fig.show()\n",
    "\n",
    "    # plot errors\n",
    "    bst.df_pm.assign(horizon=bst.df_pm.horizon.dt.days).set_index(\"horizon\")[\n",
    "        [\"rmse\", \"mae\"]\n",
    "    ].plot()\n",
    "    pyplot.title(f\"誤差: {rate_type}\")\n",
    "    pyplot.show()\n",
    "    bst.df_pm.assign(horizon=bst.df_pm.horizon.dt.days).set_index(\"horizon\")[\n",
    "        [\"mape\", \"smape\"]\n",
    "    ].plot()\n",
    "    pyplot.title(f\"誤差率: {rate_type}\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_visualization(bst: BestEstimator):\n",
    "    optuna.visualization.plot_contour(bst.study).show()\n",
    "    optuna.visualization.plot_edf(bst.study).show()\n",
    "    optuna.visualization.plot_optimization_history(bst.study).show()\n",
    "    optuna.visualization.plot_parallel_coordinate(bst.study).show()\n",
    "    optuna.visualization.plot_param_importances(bst.study).show()\n",
    "    optuna.visualization.plot_slice(bst.study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame({k: [v] for k, v in bst.study.best_params.items()}).T  # .plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "for rt in bests.keys():\n",
    "    bst: BestEstimator = bests[rt]\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"\"\"---\n",
    "# 国債金利：{rt} \n",
    "\"\"\"\n",
    "        )\n",
    "    )\n",
    "    display(\n",
    "        pandas.DataFrame(\n",
    "            {k: [v] for k, v in bst.study.best_params.items()}, index=[\"value\"]\n",
    "        ).T\n",
    "    )\n",
    "    optuna_visualization(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_type = \"10年\"\n",
    "bst: BestEstimator = bests[rate_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changepoint data\n",
    "changepoints_threshold = 0.01\n",
    "signif_changepoints = bst.model.changepoints[\n",
    "    numpy.abs(numpy.nanmean(bst.model.params[\"delta\"], axis=0))\n",
    "    >= changepoints_threshold\n",
    "]\n",
    "df_cp = signif_changepoints.reset_index(drop=True)\n",
    "df_cp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig: go.Figure = plot_plotly(bst.model, bst.forecast, trend=True, changepoints=True)\n",
    "fig.update_layout(title=f\"予測 : {rate_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components_plotly(model, forecast).update_layout(title=f\"コンポーネント : {rate_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_end_date = datetime.now()\n",
    "g_end_date.strftime(\"%Y/%m/%d %T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.model.n_changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dates = pandas.date_range(\n",
    "    start=bst.df.ds.min(), end=bst.future.ds.max(), freq=\"W-MON\", name=\"ds\"\n",
    ")\n",
    "base_dates = base_dates.to_frame().reset_index(drop=True)\n",
    "base_dates.head(3)\n",
    "base_dates.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = bst.forecast.copy()\n",
    "df_forecast.index = df_forecast.ds\n",
    "seasonality_cols = [\"yearly\", \"triennial\", \"kitchen\", \"quinquennial\", \"juglar_10\"]\n",
    "\n",
    "df_forecast[\"seasonality\"] = (\n",
    "    df_forecast[seasonality_cols]\n",
    "    .sum(axis=1)\n",
    "    .rename(\"seasonality\")\n",
    "    .to_frame()\n",
    "    .set_index(df_forecast.ds)\n",
    ")\n",
    "df_forecast[\"y\"] = bst.df.y\n",
    "\n",
    "ax = df_forecast[[\"yhat\", \"y\", \"trend\"]].plot()\n",
    "ax = df_forecast[[\"seasonality\"]].plot(kind=\"line\", ax=ax)\n",
    "ax.axvline(bst.df.ds.iloc[-1], color=\"b\", linestyle=\"--\", lw=2)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_horizon_actual = True\n",
    "\n",
    "for rt in bests.keys():\n",
    "    bst: BestEstimator = bests[rt]\n",
    "    bst.df.index = bst.df.ds\n",
    "\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"\"\"---\n",
    "# 国債金利 : {rt}\n",
    "\"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_forecast = bst.forecast.copy()\n",
    "    df_forecast.index = df_forecast.ds\n",
    "    seasonality_cols = [\"yearly\", \"triennial\", \"kitchen\", \"quinquennial\", \"juglar_10\"]\n",
    "\n",
    "    df_forecast[\"seasonality\"] = (\n",
    "        df_forecast[seasonality_cols]\n",
    "        .sum(axis=1)\n",
    "        .rename(\"seasonality\")\n",
    "        .to_frame()\n",
    "        .set_index(df_forecast.ds)\n",
    "    )\n",
    "    df_forecast[\"y\"] = bst.df.y\n",
    "\n",
    "    for ctf, grp in bst.df_cv.groupby(\"cutoff\"):\n",
    "        if not use_horizon_actual:\n",
    "            grp.drop(\"y\", axis=1, inplace=True)\n",
    "\n",
    "        df_plotter = pandas.merge(base_dates, grp.reset_index(), on=\"ds\", how=\"left\")\n",
    "        setup_df_index(df_plotter)\n",
    "        # df_plotter.loc[:ctf, \"y\"] = bst.df.y.loc[:ctf]\n",
    "        df_plotter[\"y\"] = bst.df.y.loc[:ctf]\n",
    "        df_plotter = pandas.merge(\n",
    "            df_plotter,\n",
    "            df_forecast[[\"seasonality\", \"trend\"]].loc[:ctf],\n",
    "            on=\"ds\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        fig = pyplot.figure(facecolor=\"lightgrey\", figsize=(20, 10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        df_plotter[[\"yhat\", \"y\", \"seasonality\", \"trend\"]].plot(ax=ax)\n",
    "        ax.fill_between(\n",
    "            df_plotter.index,\n",
    "            df_plotter.yhat_lower,\n",
    "            df_plotter.yhat_upper,\n",
    "            color=\"#0072B2\",\n",
    "            alpha=0.2,\n",
    "            label=\"Uncertainty interval\",\n",
    "        )\n",
    "        ax.axvline(ctf, color=\"b\", linestyle=\"--\", lw=2)\n",
    "        ax.set_ylim(-1.5, 3)\n",
    "\n",
    "        pyplot.title(f\"cutoff: {ctf}\", fontsize=20)\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "experiment_name = \"jgbcm_interest_rate\"\n",
    "\n",
    "tracking_uri = f\"sqlite:///../data/experiment.db\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(name=experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Enable to infer input signature of `_ds`, for MLflow\n",
    "str_cols = [\"基準日\", \"ds\"]\n",
    "value_cols = [col for col in _df.columns if col not in str_cols]\n",
    "_df = _df.assign(**{col: _df[col].astype(float) for col in value_cols}).assign(\n",
    "    **{col: _df[col].astype(str) for col in str_cols}\n",
    ")\n",
    "_df[value_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "\n",
    "desc = \"Predict the interest rate for jgbcm\"\n",
    "with mlflow.start_run(\n",
    "    experiment_id=experiment_id, run_name=\"trial\", description=desc\n",
    ") as mlf:\n",
    "    ds: PandasDataset = mlflow.data.from_pandas(_df, source=url)\n",
    "    mlflow.log_input(ds, context=\"simulation\")\n",
    "\n",
    "    mlflow.set_tag(\"start\", g_start_date)\n",
    "    mlflow.set_tag(\"end\", g_end_date)\n",
    "    duration = round((g_end_date - g_start_date).seconds / 60, 0)\n",
    "    mlflow.set_tag(\"duration\", f\"{duration} mins\")\n",
    "\n",
    "    mlflow.log_param(\"period_type\", f\"{period_type}\")\n",
    "    for rt in bests.keys():\n",
    "        bst: BestEstimator = bests[rt]\n",
    "\n",
    "        # params\n",
    "        params: dict = {f\"{rt}/{k}\": v for k, v in bst.study.best_params.items()}\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(f\"{rt}/n_changepoints\", f\"{bst.model.n_changepoints}\")\n",
    "        mlflow.log_param(f\"{rt}/changepoint_range\", f\"{bst.model.changepoint_range}\")\n",
    "        params_file = \"params.yaml\"\n",
    "        with open(params_file, \"w\") as fw:\n",
    "            yaml.dump(bst.study.best_params, fw)\n",
    "        mlflow.log_artifact(params_file, artifact_path=f\"{rt}\")\n",
    "\n",
    "        # metrics\n",
    "        metrics: dict = bst.df_pm.mean().drop([\"horizon\", \"coverage\"]).to_dict()\n",
    "        metrics = {f\"{rt}/{k}\": v for k, v in metrics.items()}\n",
    "        mlflow.log_metrics(metrics=metrics)\n",
    "\n",
    "        # model\n",
    "        signature = infer_signature(bst.df, bst.forecast)\n",
    "        mlflow.prophet.log_model(bst.model, artifact_path=f\"{rt}\", signature=signature)\n",
    "        # mlflow.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f params.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
