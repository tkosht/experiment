{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トピックへの自動ラベリング\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンテンツを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n \\n\\n\\n\\n\\n\\n\\n   Google発 世界最高精度の構文解析器 “SyntaxNet” はどこがすごいのか - Eyes, JAPAN Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Eyes, JAPAN Blog\\n          \\n\\n            1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# url = \"https://ledge.ai/authorinterview-book-bert-int/\"\n",
    "# url = \"https://ainow.ai/2023/01/10/271486/\"\n",
    "# url = \"https://ja.stateofaiguides.com/20230105-cramming-bert/\"\n",
    "url = \"https://www.nowhere.co.jp/blog/archives/20160524-14722.html\"\n",
    "# url = \"https://www.yomiuri.co.jp/world/20230104-OYT1T50056/\"\n",
    "# url = \"https://www3.nhk.or.jp/kansai-news/20230104/2000069636.html\"\n",
    "# url = \"https://news.yahoo.co.jp/articles/fad0c4f41d46b686e0566bf10e4c016a641a9dab\"\n",
    "# url = \"https://news.yahoo.co.jp/articles/4d2d14fd1ca1dc9b134c5f493896a7e30fc1e781\"\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.content, \"lxml\")\n",
    "for tg in [\"script\", \"noscript\", \"meta\"]:\n",
    "    try:\n",
    "        soup.find(tg).replace_with(\" \")\n",
    "    except:\n",
    "        pass\n",
    "soup.get_text()[:200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 簡易クレンジング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google発 世界最高精度の構文解析器 “SyntaxNet” はどこがすごいのか - Eyes, JAPAN Blog',\n",
       " 'Eyes, JAPAN Blog',\n",
       " '1997年からほぼ毎日更新！会津大学発のベンチャー企業、株式会社Eyes, JAPANによるBlog',\n",
       " '。',\n",
       " 'コンピュータ、ネットワーク、Hi-Tech Gadget、魔法の様な技術などのGeekなネタから会津のローカルネタまで']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str):\n",
    "    contents = []\n",
    "    for txt in re.split(r\"(。|\\n)\", text):\n",
    "        txt = txt.strip().replace(\"\\u200b\", \"\").replace(\"\\u3000\", \" \")\n",
    "        txt = re.sub(r\"\\n+\", \"\\n\", txt)\n",
    "        txt = re.sub(r\"([\\W])\\1+\", \" \", txt)\n",
    "        if not txt:\n",
    "            continue\n",
    "        # contents.append(txt)\n",
    "        # contents.append(txt.split(\"\\n\")[-1])\n",
    "        contents.extend(txt.split(\"\\n\"))\n",
    "    return contents\n",
    "\n",
    "text = soup.get_text()\n",
    "contents = clean_text(text)\n",
    "contents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickup wiki data to analyze topic\n",
    "# wdb = WikiDb(mode=\"train\")\n",
    "# records = wdb.select_by_document_id(document_ids=[\n",
    "#     \"Doc01GN7P2K02Y2FC8BXHMZ5V1A34\",    # 南部煎餅\n",
    "#     \"Doc01GN7P3C1ZPVGB8AXJC75M9ZQ9\",    # 龍が如く OF THE END\n",
    "#     \"Doc01GN7P3C0YPAWH4KT16P7NNQBK\",    # 自動運転車\n",
    "#     \"Doc01GN7P3BS2JNYS3HYV0RM1TT7T\",    # デュケイン大学\n",
    "#     \"Doc01GN7P3BK88YCXKS64H6G2HK0Y\",    # 深蒸し茶\n",
    "#     ])\n",
    "# X: TextSequences = [WikiRecord(*rec).paragraph.splitlines() for rec in records]\n",
    "# pipe_topic.fit(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トピックモデルのパイプラインを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "from app.component.models.model import TextSequences\n",
    "from app.component.models.pipeline import Pipeline\n",
    "from app.component.models.vectorizer import VectorizerBoW, VectorizerWord2vec\n",
    "from app.domain.models.tokenizer import TokenizerWord\n",
    "from app.domain.models.topic_model import TopicModel\n",
    "from app.infra.wikidb import WikiDb, WikiRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_topic = Pipeline(\n",
    "    steps=[\n",
    "        (TokenizerWord(use_stoppoes=True), None),\n",
    "        (VectorizerBoW(), None),\n",
    "        (TopicModel(n_topics=10, n_epoch=2000), None),\n",
    "    ],\n",
    "    name=\"pipe_topic_sample\",\n",
    "    do_print=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/01/15 22:26:47 INFO Start to fit n_step=0 model=JpTokenizerMeCab(use_stoppoes=True, filterpos=[], use_orgform=False)\n",
      "2023/01/15 22:26:47 INFO End to fit n_step=0 model=JpTokenizerMeCab(use_stoppoes=True, filterpos=[], use_orgform=False)\n",
      "2023/01/15 22:26:47 INFO Start to transform n_step=0 model=JpTokenizerMeCab(use_stoppoes=True, filterpos=[], use_orgform=False)\n",
      "2023/01/15 22:26:47 INFO End to transform n_step=0 model=JpTokenizerMeCab(use_stoppoes=True, filterpos=[], use_orgform=False)\n",
      "2023/01/15 22:26:47 INFO Start to fit n_step=1 model=VectorizerBoW()\n",
      "2023/01/15 22:26:47 INFO End to fit n_step=1 model=VectorizerBoW()\n",
      "2023/01/15 22:26:47 INFO Start to transform n_step=1 model=VectorizerBoW()\n",
      "2023/01/15 22:26:47 INFO End to transform n_step=1 model=VectorizerBoW()\n",
      "2023/01/15 22:26:47 INFO Start to fit n_step=2 model=TopicModel(n_topics=10, n_epoch=2000, random_state=RandomState(MT19937))\n",
      "2023/01/15 22:26:47 INFO End to fit n_step=2 model=TopicModel(n_topics=10, n_epoch=2000, random_state=RandomState(MT19937))\n",
      "2023/01/15 22:26:47 INFO Start to transform n_step=2 model=TopicModel(n_topics=10, n_epoch=2000, random_state=RandomState(MT19937))\n",
      "2023/01/15 22:26:47 INFO End to transform n_step=2 model=TopicModel(n_topics=10, n_epoch=2000, random_state=RandomState(MT19937))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[(JpTokenizerMeCab(use_stoppoes=True, filterpos=[], use_orgform=False), None), (VectorizerBoW(), None), (TopicModel(n_topics=10, n_epoch=2000, random_state=RandomState(MT19937)), None)], name=pipe_topic_sample, do_print=True, args=(), kwargs={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X: TextSequences = [[snt] for snt in contents]\n",
    "X: TextSequences = [contents]\n",
    "# pipe_topic[:1].fit(X).transform(X)        # for debugging\n",
    "pipe_topic.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VectorizerBoW(),\n",
       " TopicModel(n_topics=10, n_epoch=2000, random_state=RandomState(MT19937)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow: VectorizerBoW = pipe_topic.get_model(1)\n",
    "model_topic: TopicModel = pipe_topic.get_model(-1)\n",
    "model_bow, model_topic\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec モデルをロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use original pretrained newsvec model (with only noun and verb tokens)\n",
    "pipe_newsvec = joblib.load(\"data/pipe_newswikivec.gz\")\n",
    "# pipe_newsvec = joblib.load(\"data/pipe_newsvec.gz\")\n",
    "pipe_newsvec\n",
    "model_vectorizer: VectorizerWord2vec = pipe_newsvec.get_model(-1)\n",
    "model_vectorizer\n",
    "w2v = model_vectorizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use original pretrained wikivec model (with only noun and verb tokens)\n",
    "# pipe_wikivec = joblib.load(\"data/pipe_wikivec.noun-verb.gz\")\n",
    "# pipe_wikivec\n",
    "# model_vectorizer: VectorizerWord2vec = pipe_wikivec.get_model(-1)\n",
    "# model_vectorizer\n",
    "# w2v = model_vectorizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use shiroyagi's word2vec pretrained model\n",
    "# from gensim.models.word2vec import Word2Vec\n",
    "# w2v = Word2Vec.load(\"data/word2vec.gensim.model\")\n",
    "# w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999994, 1.0000001 , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各トピックの確率の合計が 1 になることを確認しておく\n",
    "model_topic.get_topic_probabilities().sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickup_topic_words(model_topic: TopicModel, topn: int = -1):\n",
    "    # topn: 各トピックの上位の単語の数\n",
    "    topics = []\n",
    "    for topic_probs in model_topic.get_topic_probabilities():\n",
    "        indices = topic_probs.argsort()[::-1][:topn]\n",
    "        topic = [(model_bow.vocab[idx], topic_probs[idx]) for idx in indices]\n",
    "        topics.append(topic)\n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('June', 0.0016529982),\n",
       " ('February', 0.0016529635),\n",
       " ('August', 0.0016529604),\n",
       " ('July', 0.0016529509),\n",
       " ('SyntaxNet', 0.0016529479)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickup_topic_words(model_topic, topn=30)[0][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_topic(topics: list):\n",
    "    words = []\n",
    "    numbs = []\n",
    "    for w, p in topics:\n",
    "        do_skip: bool = False\n",
    "        do_skip |= bool(re.search(r\"^[あ-ん]\", w))    # です、ます などは、スキップ\n",
    "        do_skip |= bool(re.search(r\"[あ-ん]$\", w))    # 動名詞 などは、スキップ\n",
    "        do_skip |= w[0].isnumeric()                  # 数字から始まるラベルはスキップ\n",
    "        if do_skip:\n",
    "            continue\n",
    "        words.append(w)\n",
    "        numbs.append(p)\n",
    "    return words, numbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import re\n",
    "\n",
    "\n",
    "def estimate_topic_label(w2v, topics: list):\n",
    "    proper_topics = {}\n",
    "    topic_labels = []\n",
    "\n",
    "    for idx_tpc, tpc in enumerate(topics):\n",
    "        # トピック情報を、単語リストとその確率リストに分解する\n",
    "        _words, _probs = parse_topic(tpc)\n",
    "\n",
    "        # word2vec モデルに含まれる単語のみに絞る\n",
    "        words = [w for w in _words if w in w2v.wv]\n",
    "        probs = [p for w, p in zip(_words, _probs) if w in w2v.wv]\n",
    "\n",
    "        # 単語リストからベクトルに変換し、期待値ベクトルを算出\n",
    "        vectors = w2v.wv[words]\n",
    "        probs = numpy.array(probs).reshape(-1, 1)\n",
    "        topic_vector = (vectors * probs).sum(axis=0)    # 期待値ベクトル\n",
    "\n",
    "        # トピックに対する期待値ベクトルに類似するベクトルを十分な数(topn=100) を取得しておく\n",
    "        estimated_topic_labels = w2v.wv.similar_by_vector(topic_vector, topn=100)\n",
    "\n",
    "        # ラベルと類似度を取得し、最も類似度が高い最初のインデックスの要素を保持\n",
    "        labels, similarities = parse_topic(estimated_topic_labels)\n",
    "        topic_label = labels[0]\n",
    "        similarity = similarities[0]\n",
    "\n",
    "        # 重複しないトピックラベル集合(proper_topics)として記録しておく\n",
    "        if topic_label not in proper_topics:\n",
    "            proper_topics[topic_label] = (idx_tpc, similarity, words, probs)\n",
    "\n",
    "        # 重複を許すトピックラベル(topic_labels)として記録しておく\n",
    "        topic_labels.append((topic_label, similarity))\n",
    "\n",
    "    return topic_labels, proper_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トピック数を自動で特定するサンプル\n",
    "# # トピック数が proper_topics と一致するまで、減らしていくことで、トピック数を特定する\n",
    "\n",
    "# w2v : is already loaded\n",
    "topic_label_counter = {}\n",
    "\n",
    "n_topic_words = 17      # to calculate the average over\n",
    "n_topics = 10            # default topic numbers\n",
    "\n",
    "\n",
    "rs = numpy.random.RandomState(12345)\n",
    "\n",
    "while True:\n",
    "    # トピックモデルのパイプラインを構築\n",
    "    pipe_topic = Pipeline(\n",
    "        steps=[\n",
    "            (TokenizerWord(use_stoppoes=True, use_orgform=True), None),\n",
    "            (VectorizerBoW(), None),\n",
    "            (TopicModel(n_topics=n_topics, n_epoch=2000, random_state=rs), None),\n",
    "        ],\n",
    "        name=\"pipe_topic\",\n",
    "        do_print=False,\n",
    "    )\n",
    "\n",
    "    # トピックモデルを学習\n",
    "    X: TextSequences = [contents]\n",
    "    pipe_topic.fit(X)\n",
    "\n",
    "    model_topic: TopicModel = pipe_topic.get_model(-1)\n",
    "    topics = pickup_topic_words(model_topic, topn=n_topic_words)\n",
    "    topic_labels, proper_topics = estimate_topic_label(w2v, topics)\n",
    "\n",
    "    # トピックラベルをカウント\n",
    "    for tpc in proper_topics:\n",
    "        cnt = topic_label_counter.get(tpc, 0) + 1\n",
    "        topic_label_counter[tpc] = cnt\n",
    "    \n",
    "    # ループの終了条件\n",
    "    if len(proper_topics) >= n_topics:\n",
    "        break\n",
    "\n",
    "    # 状態/処理文脈としてトピック数を更新・保持\n",
    "    n_topics = len(proper_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "topic[0]: FortniteintoPUBGwithDeep : 2 (0.832)\n",
      "     ... ['Processing', 'Apollo', 'ご', 'T', 'Boaty', 'Land', 'Language', 'Lisp', 'Prototyping', 'Git', 'NLU', 'Natural', 'UA', 'at', 'F', '2022', 'gRPC']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "topic[1]: inmultipleenvironments : 2 (0.833)\n",
      "     ... ['ご', 'F', 'UA', 'Natural', 'Git', 'Lisp', 'Land', 'NLU', 'Prototyping', 'Boaty', 'T', 'それほど', 'Language', '2022', 'Apollo', 'at', 'Processing']\n"
     ]
    }
   ],
   "source": [
    "# トピックの出力\n",
    "# # 自動付与したラベルと、各トピックの上位単語の表示\n",
    "# # 理想的には、この出力結果に違和感がないこと\n",
    "\n",
    "for idx_tpc, (lbl, sim) in enumerate(topic_labels):\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"topic[{idx_tpc}]: {lbl} : {topic_label_counter[lbl]} ({sim:0.3f})\")\n",
    "    print(\" \" * 4 + f\" ... {[_t for _t, _s in topics[idx_tpc][:20]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated n_topic: 2\n",
      "[00]: FortniteintoPUBGwithDeep: ['Processing', 'Apollo', 'T', 'Land', 'Language', 'Lisp', 'Git', 'NLU', 'Natural', 'UA', 'at', 'F']\n",
      "[01]: inmultipleenvironments: ['F', 'UA', 'Natural', 'Git', 'Lisp', 'Land', 'NLU', 'T', 'Language', 'Apollo', 'at', 'Processing']\n"
     ]
    }
   ],
   "source": [
    "# 実際に期待値ベクトルを算出するときに使った単語を表示\n",
    "# # 上記の自動付与ラベルと上位単語の関係性に違和感があるときに確認すると良いだろう\n",
    "print(\"estimated n_topic:\", len(proper_topics))\n",
    "\n",
    "for lbl, v in proper_topics.items():\n",
    "    tpc_idx, sim, words, probs = v\n",
    "    print(f\"[{tpc_idx:02d}]: {lbl}: {words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FortniteintoPUBGwithDeep : 2\n",
      "inmultipleenvironments : 2\n"
     ]
    }
   ],
   "source": [
    "for lbl, cnt in topic_label_counter.items():\n",
    "    print(f\"{lbl} : {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google発 世界最高精度の構文解析器 “SyntaxNet” はどこがすごいのか - Eyes, JAPAN Blog Eyes, JAPAN Blog 1997年からほぼ毎日更新！会津大学発のベンチャー企業、株式会社Eyes, JAPANによるBlog 。 コンピュータ、ネットワーク、Hi-Tech Gadget、魔法の様な技術などのGeekなネタから会津のローカルネタまで 。 Eyes, \n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(contents)[:200])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.10/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el28122171402774616109289454089990\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el28122171402774616109289454089990_data = {\"mdsDat\": {\"x\": [0.0024142276571946296, -0.0024142276571946296], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [53.91647380341511, 46.083526196584884]}, \"tinfo\": {\"Term\": [\"November\", \"AUGUST\", \"\\u3059\\u308b\", \"2002\", \"2021\", \"DECEMBER\", \"2018\", \"2009\", \"\\u306a\\u308b\", \"September\", \"Google\", \"2005\", \"\\u7279\\u5fb4\", \"April\", \"Stanford\", \"\\u3042\\u308b\", \"\\u306e\", \"based\", \"2017\", \"January\", \"JAPAN\", \"1998\", \"\\u308c\\u308b\", \"JUNE\", \"2008\", \"Eyes\", \"\\u6ce8\\u610f\", \"SyntaxNet\", \"October\", \"\\u3044\\u308b\", \"\\u4f55\", \"\\u3059\\u308b\", \"DECEMBER\", \"2008\", \"\\u3088\\u3046\", \"\\u306e\", \"\\u3044\\u308b\", \"\\u30d7\\u30e9\\u30c3\\u30c8\\u30d5\\u30a9\\u30fc\\u30e0\", \"\\u30cb\\u30e5\\u30fc\\u30e9\\u30eb\\u30cd\\u30c3\\u30c8\", \"SyntaxNet\", \"1999\", \"\\u7528\", \"\\u30d0\\u30a4\\u30a2\\u30b9\", \"\\u81ea\\u7136\\u8a00\\u8a9e\\u51e6\\u7406\", \"models\", \"Training\", \"\\u884c\\u3046\", \"Understanding\", \"\\u3053\\u306e\", \"\\u65b9\", \"2006\", \"\\u3059\\u3054\\u3044\", \"\\u4f1a\\u6d25\", \"Transitioin\", \"\\u3053\\u308c\", \"\\u3059\\u3067\\u306b\", \"2022\", \"\\u82f1\\u6587\", \"from\", \"2003\", \"May\", \"\\u3053\\u3053\", \"2012\", \"TO\", \"Parsey\", \"2016\", \"\\u624b\\u6cd5\", \"February\", \"2019\", \"\\u767a\\u8868\", \"July\", \"2013\", \"March\", \"October\", \"JUNE\", \"Transition\", \"January\", \"2000\", \"April\", \"September\", \"1997\", \"2001\", \"2014\", \"AUGUST\", \"November\", \"based\", \"\\u308c\\u308b\", \"2002\", \"2021\", \"November\", \"\\u306a\\u308b\", \"Google\", \"AUGUST\", \"core\", \"\\u6ce8\\u610f\", \"\\u30d5\\u30a9\\u30ef\\u30fc\\u30c9\", \"\\u7531\\u6765\", \"SQL\", \"Open Source\", \"2009\", \"\\u7279\\u5fb4\", \"2018\", \"\\u70b9\", \"THE MAN\", \"Stanford\", \"VS Code\", \"backpropagation\", \"\\u7fcc\", \"2005\", \"\\u4e00\\u822c\", \"\\u6bd4\\u3079\\u308b\", \"06158\", \"\\u7814\\u7a76\", \"\\u512a\\u308c\\u308b\", \"1603\", \"\\u5909\\u5316\", \"ON\", \"\\u3042\\u308b\", \"JAPAN\", \"2016\\u5e74\", \"MOST\", \"September\", \"2017\", \"April\", \"Eyes\", \"based\", \"January\", \"1998\", \"\\u308c\\u308b\", \"JUNE\", \"October\", \"March\", \"2010\", \"July\", \"Transition\", \"2014\", \"2004\", \"February\", \"2015\", \"May\", \"SyntaxNet\", \"\\u3059\\u308b\", \"2022\", \"DECEMBER\", \"2020\", \"\\u306e\", \"2016\"], \"Freq\": [20.0, 20.0, 31.0, 9.0, 9.0, 20.0, 10.0, 9.0, 5.0, 20.0, 5.0, 9.0, 7.0, 20.0, 6.0, 8.0, 15.0, 12.0, 9.0, 19.0, 6.0, 9.0, 11.0, 20.0, 9.0, 6.0, 3.0, 21.0, 19.0, 12.0, 2.549022924627473, 20.8901525093334, 13.587940418524761, 6.370069023578611, 5.356888572520678, 10.20616999638809, 7.684876796211169, 1.9021499772701713, 1.8827053177338247, 13.175837611842674, 6.018598963958082, 1.8518302892241796, 2.302854376706197, 1.380088362557164, 1.3782565279296473, 1.3778944825897983, 1.3750474129573769, 1.3744414906354163, 4.1059709421366835, 1.8233491265597093, 5.870830445479018, 2.7095371947133935, 0.902987332054815, 0.9000287902715945, 4.04823545812426, 0.8983745458045631, 9.416601892043918, 1.345193021434704, 1.3447061678008256, 5.813567634897545, 12.383598227365876, 2.6818257019523197, 5.7064373271856885, 3.109965642898779, 3.9727238517867436, 6.493368814115504, 5.241894329413333, 11.319803004991488, 5.163382372202215, 3.501757447170365, 11.022133085446844, 5.5409205966222155, 10.550892980405688, 10.422636421156234, 10.734735935134845, 8.855449396802305, 10.199488644900319, 5.413805656249799, 10.334533694948558, 10.207461970432686, 5.024039595253712, 5.321569963594932, 5.902565739632992, 8.908001679020483, 8.822541422374403, 6.056576698556801, 5.758176160937461, 5.7574157223176705, 5.560961003663845, 11.419652005144805, 3.378080178361195, 3.365886959953728, 11.338060174200852, 1.2535989630800268, 1.6291555729382572, 0.8134278186081215, 0.8122479352301948, 0.8106892502264507, 1.2142206198679977, 5.260812369970765, 4.044639450001805, 5.651791438810437, 0.8065195946969644, 1.2052184540595312, 3.581127468936559, 0.7940457860552391, 0.7939858588300273, 0.7928249732482151, 5.143647815094167, 1.9734941384987774, 0.7893180281811637, 1.1822299664645066, 0.7874231062340361, 0.7873930464300575, 1.5739616366044318, 0.7849332406465631, 0.7845112009987029, 4.283726954581291, 3.1151283637379628, 2.32552936055705, 1.5620553570618232, 10.10351701063309, 4.924283774345075, 9.982786833952073, 3.051634170042494, 5.979918679941743, 9.376995884886462, 4.84308517373285, 5.530161680411635, 9.602843224157668, 9.165606493702317, 9.04394133687835, 4.736973777114104, 9.329229557780858, 7.720988297867413, 5.392868118877208, 4.732299645930326, 9.046313031364422, 4.7011378735856635, 8.768018308024995, 8.015945675556909, 10.219771595123644, 6.454368774383053, 6.890941399601067, 4.648617768839661, 5.70353470203026, 4.831259021603727], \"Total\": [20.0, 20.0, 31.0, 9.0, 9.0, 20.0, 10.0, 9.0, 5.0, 20.0, 5.0, 9.0, 7.0, 20.0, 6.0, 8.0, 15.0, 12.0, 9.0, 19.0, 6.0, 9.0, 11.0, 20.0, 9.0, 6.0, 3.0, 21.0, 19.0, 12.0, 3.793985345306787, 31.109924104457043, 20.478881818125828, 9.851515296780791, 8.33437535433767, 15.909704698418349, 12.117334851310176, 3.0284545682026005, 3.0274705721554263, 21.19178328739958, 9.833954734089215, 3.025937952366596, 3.7818366518753734, 2.268998994218421, 2.2689340989166125, 2.2689610514880907, 2.2688000297478284, 2.2687761614222675, 6.805225332623779, 3.024522541013128, 9.826721426405635, 4.535475691269237, 1.5118838676847546, 1.5117305068088216, 6.802325279699011, 1.5116660171589267, 15.87097066642697, 2.2672945824483985, 2.267331394647671, 9.824123403416591, 21.151616535390872, 4.53414487486257, 9.81872047431986, 5.288752370995223, 6.798659779185764, 11.32462783571923, 9.062223963045675, 20.366116036355912, 9.058256856812186, 6.041896493687872, 20.351362643227702, 9.81046586473893, 19.59483431728404, 19.58824291485855, 20.337579159292513, 16.576437694669718, 19.576484529786782, 9.803982601081852, 20.31732052890063, 20.310978981065773, 9.051291107955048, 9.79948113566809, 11.2954338585102, 20.246061853221335, 20.242193427519208, 12.036495378498543, 11.288337841349097, 9.732756384251187, 9.742879762190036, 20.242193427519208, 5.998152447055432, 5.998699128107582, 20.246061853221335, 2.2500068225232903, 3.0021457310580715, 1.5011952332569818, 1.5012538105387903, 1.5013503266030688, 2.2520375979360896, 9.75875923393452, 7.506881623427347, 10.509964975326945, 1.501573157742624, 2.252528965446958, 6.75930011300399, 1.502235731536047, 1.5022056840241487, 1.5022828652075457, 9.764832796966203, 3.7559591515658917, 1.502433849789581, 2.2537535119762193, 1.502537661207613, 1.5025732692481484, 3.0050663178117736, 1.5026975240951397, 1.5027049420216851, 8.265972700093226, 6.011771085266999, 4.509376496727137, 3.0056452567825334, 20.310978981065773, 9.776354421620262, 20.31732052890063, 6.0151592817205914, 12.036495378498543, 19.576484529786782, 9.780521092802754, 11.288337841349097, 20.337579159292513, 19.58824291485855, 19.59483431728404, 9.785865190871643, 20.351362643227702, 16.576437694669718, 11.2954338585102, 9.786376512307971, 20.366116036355912, 9.787889978997114, 21.151616535390872, 21.19178328739958, 31.109924104457043, 15.87097066642697, 20.478881818125828, 9.790653308569837, 15.909704698418349, 11.32462783571923], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.9382, -3.8346, -4.2647, -5.0223, -5.1955, -4.5509, -4.8347, -6.2309, -6.2412, -4.2955, -5.0791, -6.2577, -6.0398, -6.5518, -6.5531, -6.5534, -6.5554, -6.5559, -5.4615, -6.2732, -5.1039, -5.8771, -6.976, -6.9792, -5.4756, -6.9811, -4.6314, -6.5774, -6.5777, -5.1137, -4.3575, -5.8874, -5.1323, -5.7393, -5.4945, -5.0031, -5.2172, -4.4474, -5.2323, -5.6206, -4.474, -5.1618, -4.5177, -4.5299, -4.5004, -4.6929, -4.5516, -5.185, -4.5384, -4.5508, -5.2597, -5.2021, -5.0985, -4.687, -4.6966, -5.0728, -5.1233, -4.9664, -5.0012, -4.2816, -5.4996, -5.5032, -4.2888, -6.4909, -6.2289, -6.9234, -6.9249, -6.9268, -6.5228, -5.0566, -5.3195, -4.985, -6.932, -6.5303, -5.4413, -6.9475, -6.9476, -6.9491, -5.0792, -6.0371, -6.9535, -6.5495, -6.9559, -6.956, -6.2633, -6.9591, -6.9596, -5.2621, -5.5807, -5.873, -6.2709, -4.404, -5.1228, -4.4161, -5.6013, -4.9285, -4.4787, -5.1394, -5.0067, -4.4549, -4.5015, -4.5148, -5.1615, -4.4838, -4.673, -5.0319, -5.1625, -4.5146, -5.1691, -4.5458, -4.6355, -4.3926, -4.8522, -4.7867, -5.1804, -4.9758, -5.1418], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.22, 0.2195, 0.2075, 0.1817, 0.1757, 0.1738, 0.1624, 0.1527, 0.1427, 0.1425, 0.1267, 0.1267, 0.1217, 0.1205, 0.1192, 0.119, 0.117, 0.1165, 0.1125, 0.1117, 0.1026, 0.1026, 0.1023, 0.0992, 0.0988, 0.0974, 0.0957, 0.0957, 0.0953, 0.0931, 0.0824, 0.0926, 0.075, 0.0868, 0.0805, 0.0615, 0.0703, 0.0304, 0.0556, 0.0723, 0.0045, 0.0464, -0.0013, -0.0132, -0.0213, -0.0092, -0.0343, 0.0239, -0.0582, -0.0703, 0.0291, 0.0072, -0.0313, -0.2033, -0.2127, -0.0691, -0.0554, 0.2497, 0.2139, 0.2023, 0.2006, 0.1969, 0.1949, 0.1898, 0.1634, 0.162, 0.1605, 0.1585, 0.157, 0.1568, 0.1563, 0.1544, 0.1532, 0.1493, 0.1395, 0.1371, 0.1371, 0.1356, 0.1337, 0.1312, 0.131, 0.1295, 0.1286, 0.1285, 0.128, 0.1253, 0.1248, 0.1174, 0.1173, 0.1125, 0.1202, 0.0764, 0.0889, 0.0641, 0.0961, 0.0752, 0.0386, 0.0719, 0.0612, 0.0243, 0.0152, 0.0015, 0.0492, -0.0053, 0.0107, 0.0354, 0.0481, -0.0368, 0.0414, -0.1059, -0.1975, -0.3385, -0.125, -0.3145, 0.0299, -0.2511, -0.0772]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.44370424480143933, 0.44370424480143933, 0.33277135818026776, 0.6655427163605355, 0.5524073792749382, 0.4419259034199506, 0.5112202051973874, 0.5112202051973874, 0.6101309353398908, 0.40675395689326055, 0.5099968251114867, 0.40799746008918936, 0.5102310959915042, 0.40818487679320337, 0.4109832653853844, 0.6164748980780765, 0.610741513885437, 0.407161009256958, 0.5109143301110152, 0.5109143301110152, 0.5120415376240165, 0.5120415376240165, 0.6105800439073449, 0.4070533626048966, 0.6090433622897219, 0.30452168114486095, 0.4098881737025176, 0.512360217128147, 0.5109410259058189, 0.5109410259058189, 0.6110775854850494, 0.40738505699003297, 0.6115917513729271, 0.4077278342486181, 0.5311880955754066, 0.4426567463128388, 0.5108353292414418, 0.5108353292414418, 0.5298187355062816, 0.4415156129219013, 0.44352029630960754, 0.44352029630960754, 0.511438086669871, 0.511438086669871, 0.4757389783636705, 0.5708867740364046, 0.5519825810900684, 0.4415860648720547, 0.5106911502650656, 0.5106911502650656, 0.4105562315900804, 0.6158343473851207, 0.5670730662390021, 0.3780487108260014, 0.4445308952055788, 0.5433155385845964, 0.4921908863806806, 0.4921908863806806, 0.6836310753846248, 0.3418155376923124, 0.498739910199331, 0.498739910199331, 0.5401128020857637, 0.4419104744338067, 0.5001084294998497, 0.5001084294998497, 0.499020996882612, 0.499020996882612, 0.5408706667516007, 0.4917006061378188, 0.5108169439096385, 0.4597352495186746, 0.5405043481774159, 0.4422308303269766, 0.3327072606933243, 0.6654145213866486, 0.5613724424450589, 0.4593047256368664, 0.5673325242031316, 0.4254993931523487, 0.4446158481898767, 0.5434193700098493, 0.6654666342247042, 0.6654666342247042, 0.5105103118980905, 0.45945928070828146, 0.4440423201266549, 0.4440423201266549, 0.588351253028734, 0.44126343977155047, 0.6660670612851459, 0.6660670612851459, 0.492344559527247, 0.492344559527247, 0.4438329338607707, 0.5917772451476944, 0.6134453067821654, 0.3775048041736402, 0.4439454565688904, 0.4439454565688904, 0.5672415325120371, 0.3781610216746914, 0.4407303507233645, 0.4407303507233645, 0.6614935634995843, 0.6614935634995843, 0.5429393314640829, 0.4826127390791848, 0.44076626729589424, 0.44076626729589424, 0.6656744870377252, 0.6656744870377252, 0.665687802033323, 0.665687802033323, 0.4984839699035761, 0.4984839699035761, 0.4444430967896093, 0.4444430967896093, 0.4410471280733947, 0.4410471280733947, 0.44073558614042047, 0.44073558614042047, 0.48391159094378416, 0.48391159094378416, 0.6602111848988812, 0.3301055924494406, 0.6616462602754681, 0.44109750685031207, 0.5877836228029477, 0.4408377171022108, 0.5880342141146464, 0.44102566058598475, 0.6614521175309089, 0.4409680783539393, 0.6615217836803872, 0.6615217836803872, 0.6750257547877264, 0.3214408356132031, 0.5001540101690376, 0.5001540101690376, 0.6285471785654289, 0.3771283071392573, 0.599924983867894, 0.3599549903207364, 0.531522008317473, 0.531522008317473, 0.660617486556141, 0.3303087432780705, 0.5288435710220908, 0.2644217855110454, 0.6661358748324877, 0.6661358748324877, 0.6604028407753225, 0.33020142038766126, 0.5324871542242899, 0.5324871542242899, 0.6614264636154658, 0.6614264636154658, 0.7907252471892233, 0.2635750823964078, 0.6655249500747314, 0.6655249500747314, 0.6654699192388417, 0.6654699192388417, 0.5517409435464423, 0.44139275483715384, 0.6612613967591915, 0.33063069837959574, 0.6655867079539323, 0.6655867079539323, 0.33309508917395614, 0.6661901783479123, 0.6659682179610488, 0.6659682179610488, 0.39963331653421197, 0.532844422045616, 0.6609520854305004, 0.3304760427152502, 0.6661098829391857, 0.6661098829391857, 0.6620437811503234, 0.49653283586274255, 0.6655407220849855, 0.6655407220849855, 0.6656536017015986, 0.6656536017015986, 0.4407229807276577, 0.4407229807276577, 0.4410542889932385, 0.4410542889932385, 0.4407616303280583, 0.4407616303280583], \"Term\": [\"06158\", \"06158\", \"1603\", \"1603\", \"1997\", \"1997\", \"1998\", \"1998\", \"1999\", \"1999\", \"2000\", \"2000\", \"2001\", \"2001\", \"2002\", \"2002\", \"2003\", \"2003\", \"2004\", \"2004\", \"2005\", \"2005\", \"2006\", \"2006\", \"2008\", \"2008\", \"2009\", \"2009\", \"2010\", \"2010\", \"2012\", \"2012\", \"2013\", \"2013\", \"2014\", \"2014\", \"2015\", \"2015\", \"2016\", \"2016\", \"2016\\u5e74\", \"2016\\u5e74\", \"2017\", \"2017\", \"2018\", \"2018\", \"2019\", \"2019\", \"2020\", \"2020\", \"2021\", \"2021\", \"2022\", \"2022\", \"AUGUST\", \"AUGUST\", \"April\", \"April\", \"DECEMBER\", \"DECEMBER\", \"Eyes\", \"Eyes\", \"February\", \"February\", \"Google\", \"Google\", \"JAPAN\", \"JAPAN\", \"JUNE\", \"JUNE\", \"January\", \"January\", \"July\", \"July\", \"MOST\", \"MOST\", \"March\", \"March\", \"May\", \"May\", \"November\", \"November\", \"ON\", \"ON\", \"October\", \"October\", \"Open Source\", \"Open Source\", \"Parsey\", \"Parsey\", \"SQL\", \"SQL\", \"September\", \"September\", \"Stanford\", \"Stanford\", \"SyntaxNet\", \"SyntaxNet\", \"THE MAN\", \"THE MAN\", \"TO\", \"TO\", \"Training\", \"Training\", \"Transitioin\", \"Transitioin\", \"Transition\", \"Transition\", \"Understanding\", \"Understanding\", \"VS Code\", \"VS Code\", \"backpropagation\", \"backpropagation\", \"based\", \"based\", \"core\", \"core\", \"from\", \"from\", \"models\", \"models\", \"\\u3042\\u308b\", \"\\u3042\\u308b\", \"\\u3044\\u308b\", \"\\u3044\\u308b\", \"\\u3053\\u3053\", \"\\u3053\\u3053\", \"\\u3053\\u306e\", \"\\u3053\\u306e\", \"\\u3053\\u308c\", \"\\u3053\\u308c\", \"\\u3059\\u3054\\u3044\", \"\\u3059\\u3054\\u3044\", \"\\u3059\\u3067\\u306b\", \"\\u3059\\u3067\\u306b\", \"\\u3059\\u308b\", \"\\u3059\\u308b\", \"\\u306a\\u308b\", \"\\u306a\\u308b\", \"\\u306e\", \"\\u306e\", \"\\u3088\\u3046\", \"\\u3088\\u3046\", \"\\u308c\\u308b\", \"\\u308c\\u308b\", \"\\u30cb\\u30e5\\u30fc\\u30e9\\u30eb\\u30cd\\u30c3\\u30c8\", \"\\u30cb\\u30e5\\u30fc\\u30e9\\u30eb\\u30cd\\u30c3\\u30c8\", \"\\u30d0\\u30a4\\u30a2\\u30b9\", \"\\u30d0\\u30a4\\u30a2\\u30b9\", \"\\u30d5\\u30a9\\u30ef\\u30fc\\u30c9\", \"\\u30d5\\u30a9\\u30ef\\u30fc\\u30c9\", \"\\u30d7\\u30e9\\u30c3\\u30c8\\u30d5\\u30a9\\u30fc\\u30e0\", \"\\u30d7\\u30e9\\u30c3\\u30c8\\u30d5\\u30a9\\u30fc\\u30e0\", \"\\u4e00\\u822c\", \"\\u4e00\\u822c\", \"\\u4f1a\\u6d25\", \"\\u4f1a\\u6d25\", \"\\u4f55\", \"\\u4f55\", \"\\u512a\\u308c\\u308b\", \"\\u512a\\u308c\\u308b\", \"\\u5909\\u5316\", \"\\u5909\\u5316\", \"\\u624b\\u6cd5\", \"\\u624b\\u6cd5\", \"\\u65b9\", \"\\u65b9\", \"\\u6bd4\\u3079\\u308b\", \"\\u6bd4\\u3079\\u308b\", \"\\u6ce8\\u610f\", \"\\u6ce8\\u610f\", \"\\u70b9\", \"\\u70b9\", \"\\u7279\\u5fb4\", \"\\u7279\\u5fb4\", \"\\u7528\", \"\\u7528\", \"\\u7531\\u6765\", \"\\u7531\\u6765\", \"\\u767a\\u8868\", \"\\u767a\\u8868\", \"\\u7814\\u7a76\", \"\\u7814\\u7a76\", \"\\u7fcc\", \"\\u7fcc\", \"\\u81ea\\u7136\\u8a00\\u8a9e\\u51e6\\u7406\", \"\\u81ea\\u7136\\u8a00\\u8a9e\\u51e6\\u7406\", \"\\u82f1\\u6587\", \"\\u82f1\\u6587\", \"\\u884c\\u3046\", \"\\u884c\\u3046\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el28122171402774616109289454089990\", ldavis_el28122171402774616109289454089990_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el28122171402774616109289454089990\", ldavis_el28122171402774616109289454089990_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el28122171402774616109289454089990\", ldavis_el28122171402774616109289454089990_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow: VectorizerBoW = pipe_topic.get_model(1)\n",
    "model_topic: TopicModel = pipe_topic.get_model(-1)\n",
    "\n",
    "lda = model_topic.model\n",
    "bow = pipe_topic[:-1](X)\n",
    "\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, corpus=bow, dictionary=model_bow.vocab)\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_bow.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 586, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.array(bow).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
